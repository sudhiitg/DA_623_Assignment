{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78b03f6b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **Title: Convolutional Neural Networks for Image Classification on CIFAR-10**  \n",
    "**Author: Sudhanshu Chaurasia**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f081461",
   "metadata": {},
   "source": [
    "\n",
    "## **■ Motivation – Why did you pick this topic?**\n",
    "\n",
    "Image classification is a fundamental task in computer vision with wide applications in autonomous systems, medical diagnosis, security, and more. The CIFAR-10 dataset provides a great benchmark to explore deep learning techniques due to its diverse, labeled image categories. I chose this topic to deepen my understanding of convolutional neural networks (CNNs), which are a cornerstone of modern visual recognition systems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d17b7d",
   "metadata": {},
   "source": [
    "\n",
    "## **■ Connection with Past and Current Work in Multimodal Learning**\n",
    "\n",
    "Multimodal learning combines data from different modalities (e.g., images, text, audio) to improve model performance and generalization. CNNs, originally proposed for visual processing, now serve as a core component in multimodal architectures—often paired with transformers, RNNs, or embedding techniques. For example, vision-language models like CLIP and multimodal transformers like ViLT extend CNN-based image features to interact with text data. While this project focuses purely on visual data, it forms the basis for such multimodal systems and aligns with the historical shift from unimodal to integrated multimodal learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc41cf",
   "metadata": {},
   "source": [
    "# Dependencies Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a59f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5398f1b",
   "metadata": {},
   "source": [
    "# Data Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "263a147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7424e309",
   "metadata": {},
   "source": [
    "# Normalize pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8af8aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test  = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee7d7f",
   "metadata": {},
   "source": [
    "# One-hot encode labels for categorical coloumns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b163edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test  = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b801cc",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d101348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sudhi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),  # Conv(3x3x3, 32)\n",
    "    MaxPooling2D(pool_size=(2, 2)),                                  # MaxPool(2x2)\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),                           # Conv(3x3x32, 64)\n",
    "    MaxPooling2D(pool_size=(2, 2)),                                  # MaxPool(2x2)\n",
    "\n",
    "    Flatten(),                                                      # Flatten\n",
    "    Dense(512, activation='relu'),                                  # Dense(512)\n",
    "    Dense(10, activation='softmax')                                 # Dense(10) + Softmax\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ef0cc",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6466ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e24f912",
   "metadata": {},
   "source": [
    "\n",
    "# Print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "790fc91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,204,682</span> (4.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,204,682\u001b[0m (4.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,204,682</span> (4.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,204,682\u001b[0m (4.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0883469",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "923d4c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.3998 - loss: 1.6547 - val_accuracy: 0.6020 - val_loss: 1.1376\n",
      "Epoch 2/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.6118 - loss: 1.1006 - val_accuracy: 0.6316 - val_loss: 1.0240\n",
      "Epoch 3/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.6857 - loss: 0.9049 - val_accuracy: 0.6948 - val_loss: 0.8863\n",
      "Epoch 4/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 45ms/step - accuracy: 0.7437 - loss: 0.7431 - val_accuracy: 0.7160 - val_loss: 0.8301\n",
      "Epoch 5/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.7800 - loss: 0.6338 - val_accuracy: 0.7130 - val_loss: 0.8481\n",
      "Epoch 6/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.8255 - loss: 0.5112 - val_accuracy: 0.7206 - val_loss: 0.8591\n",
      "Epoch 7/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 34ms/step - accuracy: 0.8710 - loss: 0.3846 - val_accuracy: 0.7214 - val_loss: 0.8971\n",
      "Epoch 8/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 32ms/step - accuracy: 0.9035 - loss: 0.2916 - val_accuracy: 0.7296 - val_loss: 0.9224\n",
      "Epoch 9/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.9296 - loss: 0.2159 - val_accuracy: 0.7254 - val_loss: 1.0345\n",
      "Epoch 10/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.9548 - loss: 0.1484 - val_accuracy: 0.7224 - val_loss: 1.1785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x212bcb2c750>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1371f4dd",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ce856ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7111 - loss: 1.2284\n",
      "Test Accuracy: 0.7118\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e3256",
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "## **■ Learning from This Work**\n",
    "\n",
    "Through this project, I learned how to:\n",
    "- Design and train a CNN for multi-class classification  \n",
    "- Handle data preprocessing and one-hotencoding for performance gains  \n",
    "- Interpret training metrics and tune hyperparameters  \n",
    "- Learing about activation functions\n",
    "- learning about underfitting and overfitting \n",
    "- learned about adam optimiser\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb5ecca",
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "## **■ Reflections**\n",
    "\n",
    "**(a) What surprised you?**  \n",
    "I was surprised by how small changes in network architecture (e.g., filter sizes or adding batch normalization) significantly affected the performance. Also, training on even a small dataset like CIFAR-10 requires thoughtful tuning to avoid overfitting or underfitting.\n",
    "\n",
    "**(b) What can be the scope for improvement?**  \n",
    "Future improvements could include:\n",
    "- Using transfer learning with models like ResNet or VGG  \n",
    "- Adding regularization (Dropout, L2)  \n",
    "- Applying more advanced data augmentation techniques  \n",
    "- Extending this model to handle multimodal tasks by integrating image and text inputs\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
